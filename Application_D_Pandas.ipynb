{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprivoisez les Pandas et leurs _DataFrames_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Généralités\n",
    "\n",
    "Dr. X est un grand habitué des tableurs, comme Origin, Excel et Calc. Le format tableau permet de visualiser efficacement les données, de les manipuler et d'avoir une grande flexibilité sur leur contenu (texte, nombres, dates). Dr. X ne se perd pas dans ses tableaux grâce aux en-têtes des colonnes, et peut les classer, les filtrer selon ses goûts. Dr. X apprécie la possibilités de tracer des graphes à la volée, même si ceux-ci ne sont pas tout à fait de qualité _publication_. Dr. X est également heureux de savoir que ses fichiers sont rapidement exportables en un format texte, de type `.csv` ou  `.tsv`.\n",
    "\n",
    "Dr. X sera donc ravi d'en apprendre plus sur les `Pandas.Dataframe`, un type d'objet qui vont s'utiliser comme des tableurs en Python. Nous verrons dans ce tutorial : \n",
    "* comment [créer, importer et exporter des `DataFrame`](#Creer-un-dataframe) à partir de dictionnaires Python ou de fichiers `.csv` et Excel\n",
    "* comment [accéder aux données d'un `DataFrame`](#afficher-et-acceder-aux-donnees-dun-dataframe) pour afficher une ligne, une colonne ou une sélection arbitraire\n",
    "* comment [manipuler les données au sein de ces `DataFrame`](#modifier-des-dataframes) pour modifier des valeurs, ajouter ou supprimer des colonnes et des lignes ou bien les trier.\n",
    "\n",
    "L'objectif va être de 'retrouver les sensations d'Excel' le plus rapidement possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "\n",
    "### Creer un DataFrame\n",
    "\n",
    "Il est possible de créer un `DataFrame` _ex nihilo_ à partir d'un dictionnaire Python, mais nous verrons rapidement que cela n'est probablement pas la manière la plus efficace de les générer. Nous verrons rapidement ensuite comment les importer, par exemple depuis un fichier `.csv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### À partir d'un dictionnaire ou d'un tableau NumPy\n",
    "\n",
    "Reprenons notre inénarrable exemple de notre groupe de TD et de ses notes. Cela confine à l'obsession, mais c'est pour la bonne cause. Créons un dictionnaire contenant quatre clés : \n",
    "\n",
    "* `Prénom`\n",
    "* `Nom`\n",
    "* `TD_1`, la note obtenue au TD 1\n",
    "* `TD_2`, la note obtenue au TD 2\n",
    "\n",
    "Compte tenu de la manière dont on a créé notre dictionnaire, il va être assez difficile, par exemple, d'obtenir la note de `Debasish` au TD2. Il faudrait, pour cela, retrouver l'_indice_ auquel on trouve `Debasish` dans la `list` correspondant à `first_name` et examiner la note de l'indice correspondant dans `TD_2`. \n",
    "\n",
    "Il existe une fonction [numpy.where()](https://numpy.org/doc/stable/reference/generated/numpy.where.html) qui renvoie un tel indice à partir d'un objet `np.ndarray`, mais vous pouvez constater que cette solution n'est pas très intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "my_dict = {'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[18,14,13,11,16,12],\n",
    "            'TD_2':[13,17,15,13,10,9],\n",
    "            }\n",
    "\n",
    "### Numpy solution\n",
    "# Find index where `Debasish` is found in `first_names`\n",
    "# Note : np.where returns two arguments, one being empty if we are looking in 1D arrays\n",
    "idx_match,  = np.where(np.array(my_dict['first_name']) == 'Debasish') \n",
    "grade = my_dict['TD_2'][idx_match[0]] # \n",
    "print('Grade is : ' + str(grade))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est ici que les `DataFrame` vont nous aider ! On peut les créer directement à partir d'un dictionnaire, d'un tableau `np.ndarray`, ou bien d'autres types de données. La plupart du temps, on peut simplement en créer un en invoquant la commande `pd.DataFrame()` et en mettant en entrée les données que vous voulez voir converties. Regardons ce que ça donne si on essaie avec un dictionnaire : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # Not the best shorthand for French people ...\n",
    "\n",
    "my_df = pd.DataFrame(my_dict)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous voyez ici déjà que l'affichage de vos données est plutôt joli par rapport à ce que Python vous sert en général, et ressemble assez furieusement à un tableau Excel. Chouette, non ? Le format a également l'air de bien s'accommoder de mélanger des chaînes de caractère et des chiffres, mais ça, c'était déjà le cas avec les listes et bien d'autres types de variables en Python.\n",
    "\n",
    "__Exercice__ : Essayez de faire la même chose à partir d'un tableau `np.ndarray` à plusieurs dimensions, et regardez comment les données s'organisent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your beautiful code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### À partir d'un fichier .csv, voire Excel\n",
    "\n",
    "La meilleure manière de créer des `pd.DataFrame` reste cependant des les importer depuis un fichier formatté avec la bien-nommée fonction `pd.read_csv()`. Essayons de lire mon fichier de rhéologie préféré, `rheology.csv`, qui se trouve dans le sous-dossier `files` et qui a le mauvais goût d'être formatté à la _française_, c'est à dire avec des `';'` comme séparateurs entre colonnes et des `','` comme séparateurs des décimales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rheol = pd.read_csv('files/rheology.csv') # 'What could go wrong ?'\n",
    "my_rheol                                     # Really wrong things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est le bazar complet, mais ne vous inquiétez pas, il est possible de spécifier à la fois : \n",
    "\n",
    "* Le délimiteur des champs, `sep` ou `delimiter`\n",
    "* Le séparateur des décimales, `decimal`\n",
    "* Un nombre de lignes à ignorer au début du fichier, `skiprows`\n",
    "\n",
    "Il existe [bien d'autres options](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) si vous avez encore des problèmes pour des types de fichiers ou des manières de les lire bien particulières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_rheol = pd.read_csv('files/rheology.csv', decimal=',', sep=';')\n",
    "my_rheol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est bien plus satisfaisant ! \n",
    "\n",
    "Si vous ne voulez _vraiment_ pas vous embêter avec ces paramètres régionaux, vous pouvez également simplement importer un fichier _Excel_ avec `pd.read_excel()`. Celui-ci 'comprend' les fichiers : \n",
    "* `.xls`, par l'intermédiaire du module `xlrd`\n",
    "* `.xlsx`, par l'intermédiaire du module `openpyxl`\n",
    "* `.ods`, par l'intermédiaire du module `odfpy` \n",
    "\n",
    "Dans notre espace de travail, seul `openpyxl` est installé, il ne vous sera donc pas possible d'importer d'autres types de fichiers que `.xslx`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_excel('files/rheology.xlsx')\n",
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporter un DataFrame\n",
    "\n",
    "D'une manière pas tout à fait symétrique aux fonctions `pd.read_csv()` et `pd.read_excel()`, il va être possible d'exporter un DataFrame dans ces formats grâce aux _méthodes_ `.to_csv()` et `.to_excel()`  :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.to_csv('./files/my_new_csv_file.csv')\n",
    "my_data.to_excel('./files/my_new_excel_file.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "\n",
    "### Acceder aux donnees d'un DataFrame\n",
    "\n",
    "Le format tableur est bien joli, mais il serait quand même chouette de pouvoir récupérer les notes de notre élève de manière efficace, non ? Voire de modifier les valeurs du tableau en cas d'erreur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accéder au début ou à la fin d'un `DataFrame` avec `.head()` et `.tail()`\n",
    "\n",
    "Parfois, lorsque votre `DataFrame` est un peu long, il serait utile d'essayer d'effectuer le traitement des données que vous avez laborieusement développé seulement sur les $n$ premières lignes de votre `DataFrame`, ou sur les $n$ dernières. Pour cela, vous pouvez employer les méthodes `.head()` et `.tail()`. Notez qu'elles renvoient bien des sous-parties du `DataFrame` initial, ce n'est pas juste une 'option d'affichage' !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_rheol = pd.read_csv('files/rheology.csv', decimal=',', sep=';')\n",
    "\n",
    "beginning = my_rheol.head(10)\n",
    "beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexation standard (`[]`)\n",
    "\n",
    "Pour accéder à une colonne de notre tableau, on peut travailler comme avec les dictionnaires, ou comme avec des objets. Accédons aux prénoms de notre `pd.DataFrame` associé à notre inénarrable classe de TD :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[18,14,13,11,16,12],\n",
    "            'TD_2':[13,17,15,13,10,9]})\n",
    "\n",
    "my_df['first_name']   # Does work \n",
    "# my_df.first_name        # Would also have worked fine, unless column has a weird name, e.g. '1' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce que renvoie notre commande `my_df['first_name']` ressemble à un tableau Numpy `np.ndarray` ou une liste, mais ce n'est pas tout à fait le cas, car à gauche vous voyez une liste d'indices. C'est parce que cet objet est en fait une `Series` Pandas, la version '1D' des `DataFrame`. On peut d'ailleurs les convertir très simplement en tableaux Numpy, par exemple ici en écrivant `np.array(my_df['first_name'])`. \n",
    "\n",
    "On peut assez facilement sélectionner deux ou plusieurs colonnes parmi toute notre série de données. Pour cela, on remplace notre nom de colonne (par exemple, `'first_name'`) par une liste (par ex., `['first_name', 'last_name']`) et le tour est joué ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_names = my_df[['first_name', 'last_name']]   # Don't forget the extra square brackets !\n",
    "print(my_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les `np.ndarray` et les listes, on peut effectuer des coupes au niveau des colonnes avec la syntaxe `[a:b:step]`, comme par exemple ici si je ne veux regarder qu'un étudiant sur deux (même si cela est assez curieux comme pratique). Cela est possible tant que les indices du `DataFrame` sont bien ordonnés de $0$ à $n$ et qu'on n'a pas donné _explicitement_ de nom à cette colonne des indices : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La puissance des `pd.DataFrame` vient du fait que l'on peut __cumuler  facilement les sélections sur les lignes et les colonnes__. On peut tout à fait effectuer la chose suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df['first_name'][::2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexation booléenne \n",
    "\n",
    "Enfin, comme pour les [`np.ndarray`](./Application_A_Numpy.ipynb#Indexation-logique), on peut construire des _conditions_ sur construire des sur les valeurs prises dans les cases de notre tableau et effectuer des _coupes_ à partir de ces conditions. _Hein ?_ Voyez plutôt, si je veux récupérer la note de Serguey au TD1. Je vais commencer par trouver la _ligne_ correspondant à Serguey dans la liste des prénoms, puis, à partir de cette sélection de mon jeu de données initiale, faire une _nouvelle coupe_ permettant de retrouver les notes de TD1. Fort pratique ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9]})\n",
    "            \n",
    "is_serguey = my_df['first_name'] == 'Serguey'\n",
    "my_grade = my_df[is_serguey]['TD_1']\n",
    "my_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je peux même demander à appliquer _plusieurs_ conditions booléennes. Essayons par exemple de trouver un.e éventuel.le élève qui a moins que la moyenne aux deux TD, un élève en _difficulté_, même si ici les résultats sont plutôt bons. On utilisera alors [les opérateurs `~`, `&`, `|` et `^`](./Application_A_Numpy.ipynb#Combinaisons-de-conditions-sous-Numpy), et des fonctions Numpy, qui s'appliquent tout à fait correctement sur les colonnes de mon `pd.Dataframe`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belowavg_td1 = my_df['TD_1'] < np.mean(my_df['TD_1'])       # Values below average of all values for TD1\n",
    "belowavg_td2 = my_df['TD_2'] < np.mean(my_df['TD_2'])       # Values below average of all values for TD2\n",
    "my_df[belowavg_td1 & belowavg_td2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercice__ :\n",
    "\n",
    "* Pour le fichier de rhéologie `'files/rheology.csv'`, essayez de tracer avec [Matplotlib](./Application_B_Matplotlib.ipynb) la courbe contrainte ('Shearstress') vs. taux de déformation ('Shearrate') correspondant à l'étape 'Flow Curve Down Forward' (contenue dans la colonne 'Name')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and Matplotlib ... Fuuuuuuussssiiiioooonnnn ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encore plus de flexibilité : l'indexation avec `.loc[]`\n",
    "\n",
    "Pandas recommande d'utiliser cette fonction afin d'indexer les `pd.DataFrame`. Hormis le fait que cette 'fonction' soit suivie de crochets `[` et `]` et non de parenthèses `(` et `)`, celle-ci fonctionne d'une manière très similaire à l'indexation simple et booléenne. La syntaxe est en fait encore un peu plus flexible  et permet de combiner plusieurs conditions (par exemple, un nom de colonne et une sélection sur les lignes) entre les mêmes crochets, ce qui n'est pas possible avec l'indexation simple `[]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9]})\n",
    "\n",
    "is_serguey = my_df['first_name'] == 'Serguey'\n",
    "my_grade_loc = my_df.loc[is_serguey, 'TD_1']    # Combining two conditions in bet\n",
    "# my_grade_old = my_df[is_serguey, 'TD_1']        # This does not work\n",
    "\n",
    "print(my_grade_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous verrons plus loin que les indexations avec `[]` et avec `.loc[]` fonctionnent _différemment lorsqu'on essaie de modifier des valeurs_ du `pd.DataFrame`.\n",
    "\n",
    "_Note_ : Vous pouvez très bien sélectionner plusieurs colonnes. Dans ce cas, il faut faire une `list` des colonnes à afficher, que ce soit pour la méthode en `.loc[]` ou pour l'indexation directe : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_serguey = my_df['first_name'] == 'Serguey'\n",
    "columns = ['TD_1', 'TD_2']\n",
    "\n",
    "print('.loc[] result : ')\n",
    "serguey_grades_loc = my_df.loc[is_serguey, columns]\n",
    "print(serguey_grades_loc)\n",
    "\n",
    "print('Direct indexing result :')\n",
    "serguey_grades_dir = my_df[is_serguey][columns]\n",
    "print(serguey_grades_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selectionner une ligne ou plusieurs lignes a la main avec `.iloc[]`\n",
    "\n",
    "Parfois, il vous sera nécessaire de sélectionner _à la main_ une ligne de votre tableau indépendamment de toute condition. Par défaut, les lignes des `DataFrames` sont indexées par des entiers dans une colonne 'sans nom', ce qui permet d'écrire :\n",
    "\n",
    "```\n",
    "    my_df[0]\n",
    "```\n",
    "pour demander à accéder à la première ligne. \n",
    "\n",
    "Mais parfois, vos DataFrames auront des indices qui ne sont pas dans l'ordre, des indices explicitement nommés _voire_ des indices qui ne sont pas des chiffres ! Voyons un exemple pour des lignes qui ne sont pas _indexées dans l'ordre_, et essayons naïvement de demander la première ligne du tableau à l'aide de l'indexation normale `[]` puis avec `.loc[]` : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_sneaky_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9]}, index=[5,0,3,2,1,4])\n",
    "\n",
    "# my_df[0]            # Fails miserably\n",
    "my_sneaky_df.loc[0]        # Not what I want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aïe ! L'indexation normale `[]` renvoie carrément une erreur, tandis que la version avec `.loc[]` renvoie naturellement la ligne correspondant à l'indice 0, mais qui n'est plus la première ligne de mon tableau. \n",
    "\n",
    "C'est pour ce genre de cas que la fonction `.iloc[]` existe. On peut lui préciser un indice seul, mais également des _coupes_ du type `[start:stop:step]` et des listes d'indices. Commentez et dé-commentez les lignes suivantes pour examiner le fonctionnement de `.iloc[]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sneaky_df.iloc[0]\n",
    "# my_sneaky_df.iloc[::3] # Also works \n",
    "# my_sneaky_df.iloc[[0,2,4]] # Works too ! Yay !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "### Modifier des `DataFrames`\n",
    "\n",
    "Dans cette section, nous allons maintenant voir comment _modifier_ des DataFrames, c'est à dire comment : \n",
    "\n",
    "* modifier des valeurs individuelles\n",
    "* rajouter ou supprimer des colonnes ou des lignes\n",
    "* assembler des DataFrames entre eux, notamment avec `pd.concat()`\n",
    "\n",
    "Pour bien comprendre comment fonctionnent certaines de ces opérations, je vous conseille de lire d'abord la section sur la [mutabilité](./Tutorial_2_ListsTuplesDicts.ipynb#Python-et-la-mutabilite) en Python. Mais ... normalement vous l'avez déjà fait :-) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifier des valeurs individuelles dans un DataFrame \n",
    "\n",
    "Reprenons notre exemple de classe de TD. Je me suis trompé sur la note d'Aika au TD2, et je voudrais la corriger rapidement. Rien de plus simple, non ? J'accède à la bonne ligne en cherchant `my_df['first_name'] == 'Aika'` et la bonne colonne en choisissant `TD2` et le tour est joué, non ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9]})\n",
    "\n",
    "aika_row = my_df['first_name'] == 'Aika'\n",
    "my_df[aika_row]['TD_1'] = 16\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horreur ! Cela ne fonctionne pas, notre `DataFrame` initial reste inchangé. Vous remarquereez que Pandas est assez sympathique tout de même, car il vous indique la marche à suivre pour que votre code fonctionne : __pour changer des valeurs d'un `DataFrame` indexé à la fois sur les lignes et les colonnes, il faut utiliser `.loc[]`__. La raison derrière tout ça est que bien souvent, Pandas effectue une _copie_ quand on demande à voir `my_df[my_row]`. On modifie alors la copie, et non l'objet original, d'où le fait qu'on ait l'impression que l'opération ne fonctionne pas. Essayons avec `.loc[]` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.loc[aika_row,  'TD_1'] = 16\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut, bien entendu, changer de multiples valeurs d'un coup, par exemple plusieurs colonnes ou plusieurs lignes, si par exemple on avait _vraiment_ rempli au radar les notes de TD des élèves :-) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds_columns = ['TD_1', 'TD_2']\n",
    "my_students = (my_df['first_name'] == 'Olivier') | (my_df['first_name'] == 'Lu') # Parentheses are important here, otherwise operator \"|\" applies first\n",
    "\n",
    "my_df.loc[aika_row, tds_columns] = [15,13]      \n",
    "my_df.loc[my_students, 'TD_1'] = [20,20]        # Just needs to be of a \"compatible\" shape\n",
    "print(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les notes d'Olivier, d'Aika et de Lu ont bien été modifiées dans le `DataFrame` original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajouter des lignes et des colonnes \n",
    "\n",
    "Cette fois-ci, rassurez-vous, il n'y aura pas de pièges. Si vous voulez rajouter une nouvelle ligne `TD_3` à votre `DataFrame`, il suffit de la préciser. Vous pouvez choisir de spécifier toutes les valeurs, ou juste une seule pour tout le monde :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9]})\n",
    "\n",
    "my_df['TD_3'] = [11,14,13,18,18,16]\n",
    "my_df['TD_4'] = 18                      # A very lazy grading scheme indeed \n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous voulez rajouter une ligne, vous devrez être un peu plus subtil, car il n'existe pas de méthode `.append()` (celle-ci ayant été _dépréciée_ par les développeurs de Pandas). Vous pouvez par contre _joindre_ ou _concaténer_ deux (ou plusieurs) séries de données ensemble avec la fonction `pd.concat()`. Ici, on va concaténer les lignes des objets `DataFrame`, donc on doit spécifier `axis=index` comme argument de la fonction : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = pd.DataFrame({'first_name':['Jérémie', 'Marco', 'Jorrit', 'Oyeniyi', 'Elisabeth', 'Apichatpong' ],\n",
    "            'last_name': ['Fassolle', 'Leonarduzzi', 'Peeters', 'Oyewunmi', 'Battenberg', 'Weerasethakul'],\n",
    "            'TD_1':[15,9,11,13,11,12],  \n",
    "            'TD_2':[9,11,13,9,12,11],\n",
    "            'TD_3': [11,12,10,11,13,12],\n",
    "            'TD_4': 14})\n",
    "\n",
    "big_df = pd.concat((my_df, other_df), axis='index')\n",
    "big_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, les numéros des indices correspondant aux 'lignes' du gros `DataFrame` créé ont simplement été _dupliqués_ depuis les `Dataframe` initiaux, et sont donc un peu mal fichus. On peut alors s'en sortir en utilisant `.iloc[]` [comme montré ci-dessus](#selectionner-une-ligne-ou-plusieurs-lignes-a-la-main-avec-iloc). On peut également ré-indexer le tableau résultant avec l'option `ignore_index` : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_ordered_df = pd.concat((my_df, other_df), axis='index', ignore_index=True)\n",
    "big_ordered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous soupçonnez que votre `DataFrame` contient des indices en double, vous pouvez demander à Pandas de les vérifier et de les supprimer avec l'option `verify_integrity`. Si cela est le cas, alors la fonction va renvoyer une erreur. Cela va forcément créer des problèmes chez nous, car tous les indices sont initialement identiques ... : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_unique_df = pd.concat((my_df, other_df), axis='index', verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il vous faudra ré-indexer les lignes de votre deuxième (ou du premier) `DataFrame` pour que la fusion se passe correctement. Pour cela, on va utiliser la _méthode_ `.set_index()` du deuxième `DataFrame`. Cette méthode prend en entrée une des colonnes du `DataFrame`, on doit donc créer une nouvelle colonne, par exemple 'Student ID' avant d'effectuer la fusion. Et ... la nature étant _mal faite_, la méthode `.set_index()` ne modifie pas l'objet parent _par défaut_ mais crée un nouvel objet à la place. Si vous voulez directement modifier l'objet, vous devrez rajouter l'option `inplace=True` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df['ID'] = [0,1,2,3,4,5]\n",
    "other_df['ID'] = [6,7,8,9,10,11]\n",
    "\n",
    "my_df.set_index('ID', inplace=True)\n",
    "other_df.set_index('ID', inplace=True)\n",
    "\n",
    "big_unique_df = pd.concat((my_df, other_df), axis='index', verify_integrity=True)\n",
    "big_unique_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que vous avez 'forcé' ID à devenir l'index de votre `DataFrame`, il n'est plus possible de juste sélectionner une ligne avec un simple indexeur, mais par contre un appel à la méthode `.loc[]` fonctionne toujours :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_unique_df[1]        # Fails\n",
    "big_unique_df.loc[1]    # Should return data on Serguey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supprimer des lignes ou des colonnes \n",
    "\n",
    "Si vous voulez faire des coupes sombres dans données, voire des coupes claires pour y ... voir plus clair, vous pouvez cette fois-ci utiliser la méthode `.drop()` qui est bien implémentée en Pandas. Essayons d'oublier les notes du TD 2, puis ensuite Serguey Prigogine car il éclipse un peu trop le reste de la classe avec ses trop bons résultats. Il faudra une fois de plus rajouter l'option `inplace=True` pour directement modifier le `DataFrame` original :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9],\n",
    "            'TD_3': [11,12,10,11,13,12],\n",
    "            'TD_4': 14})\n",
    "\n",
    "\n",
    "my_df.drop('TD_2', axis='columns', inplace=True)    # We remove a column : specify axis='columns'\n",
    "my_df.drop(1, axis='index', inplace=True)           # We remove a row : specify axis='index'\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si votre `DataFrame` a été ré-indicé, par exemple avec 'ID', il faut quand même spécifier qu'on supprimer des lignes avec l'option `axis='index'`, mais il faut préciser les indices _réels_. Voyez ici l'exemple pour des étudiants numérotés de 22 à 27 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai'],\n",
    "            'TD_1':[11,14,13,15,12,15],\n",
    "            'TD_2':[13,17,15,14,16,9],\n",
    "            'ID':[22,23,24,25,26,27]})\n",
    "my_df.set_index('ID', inplace=True)\n",
    "my_df.drop([22,24], axis='index', inplace=True)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercice__ : \n",
    "\n",
    "* Essayez de calculer la moyenne de chaque élève et rajoutez-la à la liste de leurs notes. Vous pouvez pour cela utiliser la méthode `.mean()` disponible pour les DataFrames. Essayez également de calculer la moyenne du groupe de TD pour chaque TD. \n",
    "* Les notes du TD 1 et du TD 2 ont été inversées. Trouvez un moyen de remédier au problème avec la méthode `.drop()`. Lisez ensuite la page d'aide associée à la méthode `.rename()` et essayez de trouver une solution plus _élégante_ au problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trier des données dans un `pd.DataFrame` \n",
    "\n",
    "Les fonctions de tri des `DataFrame` sont assez puissantes et vous permettent de trier rapidement vos données selon un critère ou même une liste de critères (par ordre de priorité). \n",
    "* Pour trier simplement sur les indices (les 'lignes'), vous pouvez appeler `.sort_index()` avec pour argument `axis=index` (`axis=columns` vous permet de trier les colonnes, si cela vous intéresse ...). \n",
    "* Pour trier selon une ou plusieurs valeurs, on peut utiliser `.sort_values()`, qui prend un argument `by`. On peut lui passer un nom de colonne, par exemple, `last_name` pour trier par ordre alphabétique, ou une liste de noms de colonnes si on veut trier selon de multiples critères, par exemple `['last_name', 'first_name']` pour d'abord trier sur les noms de famille, puis ensuite sur les prénoms en cas d'égalité. Ces fonctions peuvent sans problème trier des chaînes de caractère et des nombres entre eux, mais va bien entendu peiner à dire si `'toto'` se situe avant 12 et après 13.\n",
    "\n",
    "Dans les deux cas, si vous voulez modifier le `DataFrame` (et non pas créer un nouvel objet), vous devrez spécifier l'option `inplace=True` lors de l'appel à la méthode. Si vous voulez trier les valeurs dans l'ordre décroissant, vous pouvez également rajouter l'option `ascending=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_df = pd.DataFrame({'first_name':['Olivier', 'Serguey', 'Aika', 'Debasish', 'Muhammad', 'Lu', 'Françine' ],\n",
    "            'last_name': ['Margoulin', 'Prigogine', 'Tokogawa', 'Sarker', 'Ben Amar', 'Ai', 'Margoulin'],           # Françine and Olivier are unrelated, so they say ...\n",
    "            'TD_1':[11,14,13,15,12,15,14],\n",
    "            'TD_2':[13,17,15,14,16,9,12],\n",
    "            'TD_3': [11,12,10,12,13,12,18]})\n",
    "\n",
    "print('Sort by last name only')\n",
    "print(my_df.sort_values(by='last_name'))             \n",
    "\n",
    "print('Sort by last then first name')\n",
    "print(my_df.sort_values(by=['last_name', 'TD_3']))   # Last   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercice__ : \n",
    "\n",
    "* Triez les élèves par notes de TD, en mettant la priorité sur le TD 1 puis le TD 3 et enfin le TD 2.\n",
    "* Essayez de créer _automatiquement_ le rang de chaque élève (son classement général) à partir de ses notes de TD. Puis utilisez ce rang pour indexer votre `DataFrame`. __Esprit prépa__ !!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb9c252e610b593a3421828f92740a33c32c552b9658c846af1824aa6c7c0cc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
